{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgKz8vNdb8NC"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow #library for machine learning and deep learning\n",
        "!pip install matplotlib #python library for creating visualizations\n",
        "\n",
        "import tensorflow as tf #building and training the CNN Model\n",
        "import matplotlib.pyplot as plt #display the test image\n",
        "import numpy as np #library for numerical computations\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #helps in loading, preprocessing, and augmenting image datasets\n",
        "import os #built-in os module for interacting with the file system (retrieve class labels from directory names)\n",
        "\n",
        "#Mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Set the path to your dataset on google drive (training folder)\n",
        "dataset_path = '/content/drive/MyDrive/gym_equipment_recognition/training'\n",
        "\n",
        "#Define parameters for image loading and preprocessing\n",
        "img_height, img_width = 128, 128\n",
        "batch_size = 32\n",
        "\n",
        "#Create data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, #normalizes pixel values to the range [0, 1]\n",
        "    shear_range=0.2, #applies shearing transformations to images\n",
        "    zoom_range=0.2, #zooms into images\n",
        "    horizontal_flip=True, #flips images horizontally\n",
        "    validation_split=0.2 #data split: 80% training, 20% validation\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_height, img_width), #resizes images to 128x128 pixels\n",
        "    batch_size=batch_size, #groups images into batches of 32\n",
        "    class_mode='categorical', #labels are one-hot encoded for multi-class classification\n",
        "    subset='training' #uses the training subset\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "#Build the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)), # Output: (64, 64, 32)\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)), # Output: (32, 32, 64)\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)), # Output: (16, 16, 128)\n",
        "    tf.keras.layers.Flatten(), # Output: (16 * 16 * 128) = 32768\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "#Save the model in H5 format\n",
        "model_save_path = '/content/drive/MyDrive/gym_equipment_recognition/model.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "\n",
        "#Evaluate the model based on Validation dataset\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "#Test the model with the provided image path\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = '/content/drive/MyDrive/gym_equipment_recognition/training/punching-bag/1.jpg'\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width)) #resise\n",
        "img_array = image.img_to_array(img) #convert to array\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255. #normalize\n",
        "\n",
        "prediction = model.predict(img_array) #predicts the class probabilities\n",
        "predicted_class_index = np.argmax(prediction) #retrieves the index of the highest probability\n",
        "\n",
        "#Get class labels from the directory structure (sorted)\n",
        "class_labels = sorted(os.listdir(dataset_path))\n",
        "\n",
        "print(\"Predicted class:\", class_labels[predicted_class_index])\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted Class: {class_labels[predicted_class_index]}\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    }
  ]
}